{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CMIPx data, generate climatologies and regrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, cdms2 options and path and variable declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from __future__ import print_function ; # Make py2 backward compatible\n",
    "import argparse,copy,datetime,gc,glob,os,regrid2,sys,time,pdb\n",
    "#import warnings\n",
    "import cdms2 as cdm\n",
    "import cdtime as cdt\n",
    "import cdutil as cdu\n",
    "import MV2 as mv\n",
    "import numpy as np\n",
    "os.sys.path.insert(0,'/export/durack1/git/durolib/durolib')\n",
    "from durolib import fixVarUnits,globalAttWrite,writeToLog #,trimModelList\n",
    "os.sys.path.insert(0,'/export/durack1/git/climlib/climlib')\n",
    "from wrangle import trimModelList ; # climlib\n",
    "from socket import gethostname\n",
    "\n",
    "# set cdms2 options\n",
    "cdm.setNetcdfShuffleFlag(1)\n",
    "cdm.setNetcdfDeflateFlag(1) ; # netCDF compression (use 0 for netCDF3)\n",
    "cdm.setNetcdfDeflateLevelFlag(9) ; # 9(shuf=1) 466.6KB; 9(shuf=0) 504.1KB; 4(shuf=0) 822.93KB;\n",
    "cdm.setAutoBounds(1)\n",
    "\n",
    "# Set current dirs\n",
    "workDir = '/work/durack1/Shared/190311_AR6/Chap3'\n",
    "xmlPath = '/p/user_pub/xclim/' ; #'/data_crunchy_oceanonly/crunchy_work/cmip-dyn'\n",
    "\n",
    "# Generate climatology periods\n",
    "climPeriod = ([1975,2006],[1984,2015])\n",
    "\n",
    "# Show completion\n",
    "print('** DONE **')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize argparse (once code is working for commandline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initialize argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('mipEra',help='CMIP era: either CMIP3, 5, or 6')\n",
    "parser.add_argument('activityId',help='e.g. CMIP includes all DECK simulations; ScenarioMIP all projections')\n",
    "parser.add_argument('experimentId',help='e.g. historical for CMIP5/6, 20c3m for CMIP3')\n",
    "parser.add_argument('variableId',help='e.g. tas, tos, pr, sos etc')\n",
    "parser.add_argument('-r','--realm',help='ocean assumed, specify if other',default='ocean')\n",
    "parser.add_argument('-f','--frequency',help='monthly assumed, specify if other',default='mon')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Get arguments\n",
    "if args.mipEra in ['CMIP5','CMIP6']:\n",
    "    mipEra = args.mipEra\n",
    "    print('mipEra:',mipEra)\n",
    "if args.activityId in ['CMIP','ScenarioMIP']:\n",
    "    activityId = args.activityId\n",
    "    print('activityId:',activityId)\n",
    "if args.experimentId in ['historical']:\n",
    "    experimentId = args.experimentId\n",
    "    print('experimentId:',experimentId)\n",
    "if args.realm in ['ocean']:\n",
    "    realm = args.realm\n",
    "    print('realm:',realm)\n",
    "if args.frequency in ['mon']:\n",
    "    frequency = args.frequency\n",
    "    print('frequency:',frequency)\n",
    "if args.variableId in ['so','thetao']:\n",
    "    variableId = args.variableId\n",
    "    print('variableId:',variableId)\n",
    "# Test for entries\n",
    "varsToTest = ['mipEra','activityId','experimentId','realm','frequency','variableId']\n",
    "for var in varsToTest:\n",
    "    if var in locals().keys():\n",
    "        pass\n",
    "    else:\n",
    "        print('Variable:',var,'unset, exiting..')\n",
    "        sys.exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or just test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "mipEra = 'CMIP6'\n",
    "activityId = 'CMIP'\n",
    "experimentId = 'historical'\n",
    "realm = 'ocean'\n",
    "frequency = 'mon'\n",
    "variableId = 'so'; #'thetao'\n",
    "\n",
    "# Show completion\n",
    "print('** DONE **')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOSTNAME: detect.llnl.gov\n",
      "----------\n",
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "timeNow = datetime.datetime.now();\n",
    "timeFormat = timeNow.strftime(\"%y%m%dT%H%M%S\")\n",
    "logFile = os.path.join(workDir,'_'.join([timeFormat,'CMxWOA',mipEra,activityId,experimentId,variableId,'logs.txt']))\n",
    "textToWrite = ' '.join(['TIME:',timeFormat])\n",
    "writeToLog(logFile,textToWrite)\n",
    "pypid = str(os.getpid()) ; # Returns calling python instance, so master also see os.getppid() - Parent\n",
    "writeToLog(logFile,' '.join(['MASTER PID:',pypid]))\n",
    "writeToLog(logFile,' '.join(['UV-CDAT:',sys.executable]))\n",
    "host_name = gethostname()\n",
    "print(' '.join(['HOSTNAME:',host_name]))\n",
    "writeToLog(logFile,' '.join(['HOSTNAME:',host_name]))\n",
    "print('----------')\n",
    "writeToLog(logFile,'----------')\n",
    "\n",
    "# Show completion\n",
    "print('** DONE **')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preallocate lists and fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searchPath: /p/user_pub/xclim/CMIP6/CMIP/historical/ocean/mon/so/*.xml\n",
      "so  len(fileList):      291\n",
      "so  len(fileListTrim):  237\n",
      "CMIP6_historical_so\n",
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "fileLists = []\n",
    "mip = mipEra\n",
    "var = variableId\n",
    "searchPath = os.path.join(xmlPath,mip,activityId,experimentId,realm,frequency,var,'*.xml')\n",
    "print('searchPath:',searchPath)\n",
    "writeToLog(logFile,' '.join(['searchPath:',searchPath]))\n",
    "fileList = glob.glob(searchPath) ; fileList.sort()\n",
    "print(var,' len(fileList):     ',len(fileList))\n",
    "writeToLog(logFile,''.join([var,' len(fileList):     ',str(len(fileList))]))\n",
    "fileListTrim = trimModelList(fileList)\n",
    "print(var,' len(fileListTrim): ',len(fileListTrim))\n",
    "writeToLog(logFile,''.join([var,' len(fileListTrim): ',str(len(fileListTrim))]))\n",
    "print('_'.join([mip,experimentId,var]))\n",
    "writeToLog(logFile,'_'.join([mip,experimentId,var]))\n",
    "varName = '_'.join([mip,experimentId,var])\n",
    "vars()[varName] = fileListTrim\n",
    "fileLists.extend([varName])\n",
    "del(mip,var,searchPath,fileList,fileListTrim,varName) ; gc.collect()\n",
    "\n",
    "# Deal with input lists\n",
    "for count,lst in enumerate(fileLists):\n",
    "    if count == 0:\n",
    "        fileList = copy.deepcopy(eval(lst))\n",
    "    else:\n",
    "        fileList.extend(eval(lst))\n",
    "del(count,fileLists)\n",
    "\n",
    "# Show completion\n",
    "print('** DONE **')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preload WOA18 grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read wod18\n",
      "type(s): <class 'cdms2.tvariable.TransientVariable'>\n",
      "End read wod18\n",
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "#warnings.simplefilter('error')\n",
    "woa         = cdm.open('/work/durack1/Shared/obs_data/WOD18/190312/woa18_decav_s00_01.nc')\n",
    "s           = woa('s_oa')\n",
    "print('Start read wod18')\n",
    "print('type(s):',type(s))\n",
    "s           = s[(0,)]\n",
    "print('End read wod18')\n",
    "woaLvls     = s.getLevel()\n",
    "woaGrid     = s.getGrid() ; # Get WOA target grid\n",
    "woaLat      = s.getLatitude()\n",
    "woaLon      = s.getLongitude()\n",
    "woa.close()\n",
    "\n",
    "# Show completion\n",
    "print('** DONE **')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a882a90699e6422681aa53c8c189cc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, continuous_update=False, description='j', max=199), Label(valâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<vcs.displayplot.Dp at 0x7f13f12975f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% Loop through files\n",
    "for count,filePath in enumerate(fileList):\n",
    "    print(count,filePath)\n",
    "    # Add AWI, BCC kludge - have to fix grid issue - *** TypeError: 'NoneType' object is not subscriptable\n",
    "    if any(x in filePath for x in ['.AWI-CM-1-1-MR.','.bcc-csm1-1.','.bcc-csm1-1-m.','.BCC-CSM2-MR.','.BCC-ESM1.']):\n",
    "        strTxt = ' '.join([str(count),'** Known grid issue with:',filePath.split('/')[-1],'skipping..**'])\n",
    "        print(strTxt)\n",
    "        writeToLog(logFile,strTxt)\n",
    "        continue\n",
    "    writeToLog(logFile,' '.join([str(count),filePath]))\n",
    "    var = filePath.split('/')[-2]\n",
    "    mipEra = filePath.split('/')[4]\n",
    "    # Generate climatological period\n",
    "    if mipEra == 'CMIP5':\n",
    "        startYr = climPeriod[0][0]\n",
    "        startYrCt = cdt.comptime(startYr)\n",
    "        endYr = climPeriod[0][1]\n",
    "        endYrCt   = cdt.comptime(endYr)\n",
    "    elif mipEra == 'CMIP6':\n",
    "        startYr = climPeriod[1][0]\n",
    "        startYrCt = cdt.comptime(startYr)\n",
    "        endYr = climPeriod[1][1]\n",
    "        endYrCt   = cdt.comptime(endYr)\n",
    "    #print('open file')\n",
    "    fH = cdm.open(filePath)\n",
    "    mntPathStr = ' '.join(['Mount path:',fH.directory])\n",
    "    print(mntPathStr)\n",
    "    writeToLog(logFile,mntPathStr)\n",
    "    # Test that path exists\n",
    "    if not os.path.exists(fH.directory):\n",
    "        prStr = 'Data path no longer available'\n",
    "        print(prStr)\n",
    "        writeToLog(logFile,prStr)\n",
    "        continue\n",
    "    startTime = time.time()\n",
    "    #print('start data read')\n",
    "    dH = fH[var]\n",
    "    #print('dH.max:',dH.max())\n",
    "    #print('dH.min:',dH.min())\n",
    "    #print('dH loaded')\n",
    "    #pdb.set_trace()\n",
    "    print('dH shape:',dH.shape)\n",
    "    writeToLog(logFile,' '.join(['dH shape:',str(dH.shape)]))\n",
    "    # Specify levels for per-level read/write\n",
    "    levs = dH.getLevel()\n",
    "    # Preallocate WOA and model grids\n",
    "    print('s.shape (WOA):',s.shape)\n",
    "    print('Time:',datetime.datetime.now().strftime('%H%M%S'))\n",
    "#    climInterp = np.ma.zeros([s.shape[0],s.shape[1],s.shape[2]])\n",
    "#    clim = np.ma.zeros([dH.shape[1],dH.shape[2],dH.shape[3]])\n",
    "# Loop over levels\n",
    "#    for lvl in range(len(levs)):\n",
    "#        print('lvl:',lvl)\n",
    "##        if lvl % 10 == 0:\n",
    "##            print('lvl: %02d' % lvl)\n",
    "##        try:\n",
    "#        d = fH(var,time=(startYrCt,endYrCt,'con'),lev=slice(lvl,lvl+1))\n",
    "#        times = d.getTime()\n",
    "#        print('starts :',times.asComponentTime()[0])\n",
    "#        print('ends   :',times.asComponentTime()[-1])\n",
    "#        climLvl = cdu.YEAR.climatology(d)\n",
    "#        clim[lvl,] = climLvl\n",
    "#        climInterp[lvl,] = climLvl.regrid(woaGrid,regridTool='ESMF',regridMethod='linear')\n",
    "#        del(d,climLvl) ; gc.collect()\n",
    "\n",
    "    # Test valid dates\n",
    "    timeCheck = dH.getTime()\n",
    "    #pdb.set_trace()\n",
    "    startYrChk = timeCheck.asComponentTime()[0].year\n",
    "    endYrChk = timeCheck.asComponentTime()[-1].year\n",
    "    # Test\n",
    "    if (endYrChk < endYrCt.year-1) or (startYrChk > startYrCt.year):\n",
    "        # Skip file and go to next, note 2006-1 to give 2005 coverage\n",
    "        reportStr = ''.join(['*****\\n',filePath.split('/')[-1],\n",
    "                              ' does not cover temporal range; target: ',\n",
    "                              str(endYrCt.year-1),' vs file: ',str(endYrChk),\n",
    "                              ' skipping to next file..\\n','*****',])\n",
    "        print(reportStr)\n",
    "        writeToLog(logFile,reportStr)\n",
    "        continue\n",
    "\n",
    "    # No level looping\n",
    "    print('var:',var)\n",
    "    print('startYrCt:',startYrCt)\n",
    "    print('endYrCt:  ',endYrCt)\n",
    "    d1 = fH(var,time=(startYrCt,endYrCt,'con'))\n",
    "    '''\n",
    "    print('d1.max:',d1.max())\n",
    "    print('d1.min:',d1.min())\n",
    "    d2 = fH(var,time=('1984','2015','con')) ; # Outside lim\n",
    "    print('d2.max:',d2.max())\n",
    "    print('d2.min:',d2.min())\n",
    "    d3 = fH(var,time=('1984','2015')) ; # Outside lim\n",
    "    print('d3.max:',d3.max())\n",
    "    print('d3.min:',d3.min())\n",
    "    d4 = fH(var,time=('1850','1851')) ; # Within lim\n",
    "    print('d4.max:',d4.max())\n",
    "    print('d4.min:',d4.min())\n",
    "    d5 = fH(var,time=('1984','2014')) ; # On lim\n",
    "    print('d5.max:',d5.max())\n",
    "    print('d5.min:',d5.min())\n",
    "    d6 = fH(var,time=('1984','2013')) ; # Within lim\n",
    "    print('d6.max:',d6.max())\n",
    "    print('d6.min:',d6.min())\n",
    "    pdb.set_trace()\n",
    "    '''\n",
    "    # Add test for 0-valued arrays\n",
    "    if d1.max == 0 and d1.min == 0:\n",
    "        # Skip file and go to next, note 2006-1 to give 2005 coverage\n",
    "        reportStr = ''.join(['*****\\n',filePath.split('/')[-1],\n",
    "                              ' has zero-valued arrays,',\n",
    "                              ' skipping to next file..\\n','*****',])\n",
    "        print(reportStr)\n",
    "        writeToLog(logFile,reportStr)\n",
    "        continue\n",
    "    # Validate variable axes\n",
    "    #for i in range(len(d1.shape)):\n",
    "    #    ax = d1.getAxis(i)\n",
    "    #    print(ax.id,len(ax))\n",
    "    #pdb.set_trace()\n",
    "    d1,varFixed = fixVarUnits(d1,var,report=True,logFile=logFile)\n",
    "    #print('d1.max():',d1.max().max().max(),'d1.min():',d1.min().min().min()) ; Moved below for direct comparison\n",
    "    #print('d1 loaded')\n",
    "    #pdb.set_trace()\n",
    "    times = d1.getTime()\n",
    "    print('starts :',times.asComponentTime()[0])\n",
    "    print('ends   :',times.asComponentTime()[-1])\n",
    "    print('Time:',datetime.datetime.now().strftime('%H%M%S'),'cdu start')\n",
    "    climLvl = cdu.YEAR.climatology(d1)\n",
    "    #print('climLvl created')\n",
    "    #pdb.set_trace()\n",
    "    print('Time:',datetime.datetime.now().strftime('%H%M%S'),'cdu end')\n",
    "    clim = climLvl\n",
    "    #pdb.set_trace()\n",
    "    climInterp = climLvl.regrid(woaGrid,regridTool='ESMF',regridMethod='linear')\n",
    "    #climInterp = climLvl.regrid(woaGrid,regridTool='ESMF',regridMethod='conservative') ; # Chat to Pete 191127\n",
    "    #print('climInterp created')\n",
    "    precision = 8.3 ; # Updated to deal with Kelvin 300.xx\n",
    "    d1Max = np.max(d1) #d1.max().max().max()\n",
    "    d1Mean = np.mean(d1.data) #1 #np.mean(d1) #np.mean(d1.data)\n",
    "    d1Median = np.median(d1.data) #1 #np.median(d1) #np.median(d1.data)\n",
    "    d1Min = np.min(d1) #1.min().min().min()\n",
    "    d1Str = ''.join(['d1.max()'.ljust(16),':',\n",
    "                     '{:{}f}'.format(d1Max,precision),\n",
    "                     ' mean:','{:{}f}'.format(d1Mean,precision),\n",
    "                     ' median:','{:{}f}'.format(d1Median,precision), # This method is oblivious to the mask/missing values\n",
    "                     ' min:','{:{}f}'.format(d1Min,precision)])\n",
    "    print(d1Str)\n",
    "    writeToLog(logFile,d1Str)\n",
    "    climInterpMax = np.max(climInterp) #climInterp.max().max().max()\n",
    "    climInterpMean = np.mean(climInterp.data)\n",
    "    climInterpMedian = np.median(climInterp.data)\n",
    "    climInterpMin = np.min(climInterp) #climInterp.min().min().min()\n",
    "    climInterpStr = ''.join(['climInterp.max()'.ljust(16),':',\n",
    "                             '{:{}f}'.format(climInterpMax,precision),\n",
    "                             ' mean:','{:{}f}'.format(climInterpMean,precision),\n",
    "                             ' median:','{:{}f}'.format(climInterpMedian,precision),\n",
    "                             ' min:','{:{}f}'.format(climInterpMin,precision)])\n",
    "    print(climInterpStr)\n",
    "    writeToLog(logFile,climInterpStr)\n",
    "    del(d1,climLvl) ; gc.collect()\n",
    "\n",
    "    # Regrid vertically\n",
    "    pr = regrid2.pressure.PressureRegridder(levs,woaLvls)\n",
    "    #climInterp2 = pr(climInterp)\n",
    "    #climInterp2 = pr.rgrd(climInterp,None,None) ; # This interpolation is currently not missing data aware\n",
    "    climInterp2 = pr.rgrd(climInterp,climInterp.missing,'equal') ; # By default output missing value will be missingValueIn\n",
    "    # rgrd(dataIn,missingValueIn,missingMatch,logYes='yes',positionIn=None,missingValueOut=None)\n",
    "    # https://github.com/CDAT/cdms/blob/master/regrid2/Lib/pressure.py#L150-L222\n",
    "    #pdb.set_trace()\n",
    "    climInterp2Max = np.max(climInterp2)\n",
    "    climInterp2Mean = np.mean(climInterp2)\n",
    "    climInterp2Median = np.median(climInterp2)\n",
    "    climInterp2Min = np.min(climInterp2)\n",
    "    climInterp2Str = ''.join(['climInterp2.max():',\n",
    "                              '{:{}f}'.format(climInterp2Max,precision),\n",
    "                              ' mean:','{:{}f}'.format(climInterp2Mean,precision),\n",
    "                              ' median:','{:{}f}'.format(climInterp2Median,precision),\n",
    "                              ' min:','{:{}f}'.format(climInterp2Min,precision)])\n",
    "    print(climInterp2Str)\n",
    "    writeToLog(logFile,climInterp2Str)\n",
    "    #print('climInterp2 created')\n",
    "    #pdb.set_trace()\n",
    "    # Mask invalid datapoints\n",
    "    climInterp3 = mv.masked_where(mv.equal(climInterp2,1e+20),climInterp2)\n",
    "    climInterp3 = mv.masked_where(mv.greater(climInterp3,1e+10),climInterp3) ; # Add great to catch fringe values, switched from 1e+20 to 1e+10\n",
    "    print('climInterp3.missing:',climInterp3.missing)\n",
    "    #climInterp3.setMissing(1e+20) ; # Specifically assign missing value\n",
    "    #print('climInterp3 created')\n",
    "    pdb.set_trace()\n",
    "    '''\n",
    "    import matplotlib.pyplot as plt\n",
    "    climSlice = clim[0,0,:,:] ; plt.figure(1) ; plt.contourf(clim.getLongitude().data,clim.getLatitude().data,climSlice,20) ; #clim\n",
    "    plt.show()\n",
    "    climInterpSlice = climInterp[0,0,:,:] ; plt.figure(2) ; plt.contourf(climInterp.getLongitude().getData(),climInterp.getLatitude().getData(),climInterpSlice,20) ; #climInterp\n",
    "    plt.show()\n",
    "    #climInterp2Slice = climInterp2[0,0,:,:] ; plt.figure(3) ; plt.contourf(climInterp.getLongitude().getData(),climInterp.getLatitude().getData(),climInterp2Slice,20) ; #climInterp2\n",
    "    #plt.show()\n",
    "    climInterp3Slice = climInterp3[0,0,:,:] ; plt.figure(4) ; plt.contourf(climInterp.getLongitude().getData(),climInterp.getLatitude().getData(),climInterp3Slice,20) ; #climInterp3\n",
    "    plt.show()\n",
    "    '''\n",
    "    #climInterp3 = mv.masked_where(mv.greater(climInterp2,100),climInterp2) ; # Fudge for deep BNU fields\n",
    "    climInterp3.id = \"\".join([var,'_mean_WOAGrid'])\n",
    "    climInterp3Max = np.max(climInterp3)\n",
    "    climInterp3Mean = np.mean(climInterp3)\n",
    "    #climInterp3Median = np.median(climInterp3)\n",
    "    climInterp3Median = np.median(climInterp3.data) ; # Fix for MIROC-ES2L.historical.r1i1p1f2.so.gn.v20190823 (184)\n",
    "    climInterp3Min = np.min(climInterp3)\n",
    "    climInterp3Str = ''.join(['climInterp3.max():',\n",
    "                              '{:{}f}'.format(climInterp3Max,precision),\n",
    "                              ' mean:','{:{}f}'.format(climInterp3Mean,precision),\n",
    "                              ' median:','{:{}f}'.format(climInterp3Median,precision),\n",
    "                              ' min:','{:{}f}'.format(climInterp3Min,precision)])\n",
    "    print(climInterp3Str)\n",
    "    writeToLog(logFile,climInterp3Str)\n",
    "\n",
    "    # Redress WOA grid\n",
    "    #pdb.set_trace()\n",
    "    print('climInterp3.shape:',climInterp3.shape)\n",
    "    #timeAx = cdm.createAxis(np.mean([startYrCt.absvalue,endYrCt.absvalue]),[startYrCt,endYrCt],id='time')\n",
    "    # TypeError: len() of unsized object\n",
    "    startYrCtYear = startYrCt.year\n",
    "    startYrCtMonth = startYrCt.month\n",
    "    startYrCtDay = startYrCt.day\n",
    "    #pdb.set_trace()\n",
    "    calStr = ' '.join(['days since','-'.join([str(startYrCtYear),str(startYrCtMonth),str(startYrCtDay)])])\n",
    "    timeMean = np.mean([startYrCt.torel(calStr).value,endYrCt.torel(calStr).value])\n",
    "    #timeMean = cdt.relativetime(timeMean,calStr)\n",
    "    timeBounds = np.array([startYrCt.torel(calStr).value,endYrCt.torel(calStr).value])\n",
    "    timeAx = cdm.createAxis((timeMean,),bounds=timeBounds,id='time')\n",
    "    timeAx.units = calStr ; # Assign units to ndarray type NOT reltime type\n",
    "    #print(timeAx)\n",
    "    #pdb.set_trace()\n",
    "    climInterp3.setAxis(0,timeAx)\n",
    "    climInterp3.setAxis(1,woaLvls)\n",
    "    climInterp3.setAxis(2,woaLat)\n",
    "    climInterp3.setAxis(3,woaLon)\n",
    "\n",
    "    # Write out data\n",
    "    modId = '.'.join(['.'.join(filePath.split('/')[-1].split('.')[:-3]),'-'.join([str(startYr),str(endYr-1),'clim']),'nc'])\n",
    "    outFMod = os.path.join(workDir,'ncs',mipEra,experimentId,'modGrid')\n",
    "    outFModId = os.path.join(outFMod,modId)\n",
    "    woaId = '.'.join(['.'.join(filePath.split('/')[-1].split('.')[:-3]),'-'.join([str(startYr),str(endYr-1),'woaClim']),'nc'])\n",
    "    outFWoa = os.path.join(workDir,'ncs',mipEra,experimentId,'woaGrid')\n",
    "    outFWoaId = os.path.join(outFWoa,woaId)\n",
    "    #pdb.set_trace()\n",
    "\n",
    "    # Write out data\n",
    "    # Check file exists\n",
    "    #pdb.set_trace()\n",
    "    if os.path.exists(outFModId):\n",
    "        print('** File exists.. removing **')\n",
    "        os.remove(outFModId)\n",
    "    if not os.path.exists(outFMod):\n",
    "        os.makedirs(outFMod)\n",
    "    modIdH = cdm.open(outFModId,'w')\n",
    "    # Copy across global attributes from source file - do this first, then write again so new info overwrites\n",
    "    for i,key in enumerate(fH.attributes.keys()):\n",
    "        setattr(modIdH,key,fH.attributes.get(key))\n",
    "    del(i,key) ; gc.collect()\n",
    "    globalAttWrite(modIdH,options=None)\n",
    "    modIdH.climStart = str(times.asComponentTime()[0])\n",
    "    modIdH.climEnd = str(times.asComponentTime()[-1])\n",
    "    modIdH.write(clim.astype('float32'))\n",
    "    modIdH.close()\n",
    "    # Check file exists\n",
    "    if os.path.exists(outFWoaId):\n",
    "        print('** File exists.. removing **')\n",
    "        os.remove(outFWoaId)\n",
    "    if not os.path.exists(outFWoa):\n",
    "        os.makedirs(outFWoa)\n",
    "    woaIdH = cdm.open(outFWoaId,'w')\n",
    "    # Copy across global attributes from source file - do this first, then write again so new info overwrites\n",
    "    for i,key in enumerate(fH.attributes.keys()):\n",
    "        setattr(woaIdH,key,fH.attributes.get(key))\n",
    "    del(i,key) ; gc.collect()\n",
    "    globalAttWrite(woaIdH,options=None)\n",
    "    woaIdH.climStart = str(times.asComponentTime()[0])\n",
    "    woaIdH.climEnd = str(times.asComponentTime()[-1])\n",
    "    #pdb.set_trace()\n",
    "    woaIdH.write(climInterp3.astype('float32'))\n",
    "    woaIdH.close()\n",
    "    fH.close()\n",
    "\n",
    "    #print('end data read')\n",
    "    endTime = time.time()\n",
    "    print('Time taken (secs):','{:.2f}'.format(endTime-startTime))\n",
    "    writeToLog(logFile,' '.join(['Time taken (secs):','{:.2f}'.format(endTime-startTime)]))\n",
    "    print('----------')\n",
    "    writeToLog(logFile,'----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```For visual debugging\n",
    "    import vcs\n",
    "    #from IPython.core.display import display\n",
    "    from IPython.core.display import display as display_jupyter\n",
    "    climSlice = clim[0,0,:,:]\n",
    "    x = vcs.init()\n",
    "    bobIsYourUncle = x.plot(climSlice)\n",
    "    display_jupyter(bobIsYourUncle)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "climSlice = clim[0,0,:,:] ; plt.figure(1) ; plt.contourf(clim.getLongitude().data,clim.getLatitude().data,climSlice,20) ; #clim\n",
    "plt.show()\n",
    "climInterpSlice = climInterp[0,0,:,:] ; plt.figure(2) ; plt.contourf(climInterp.getLongitude().getData(),climInterp.getLatitude().getData(),climInterpSlice,20) ; #climInterp\n",
    "plt.show()\n",
    "#climInterp2Slice = climInterp2[0,0,:,:] ; plt.figure(3) ; plt.contourf(climInterp.getLongitude().getData(),climInterp.getLatitude().getData(),climInterp2Slice,20) ; #climInterp2\n",
    "#plt.show()\n",
    "climInterp3Slice = climInterp3[0,0,:,:] ; plt.figure(4) ; plt.contourf(climInterp.getLongitude().getData(),climInterp.getLatitude().getData(),climInterp3Slice,20) ; #climInterp3\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cdat82MesaPy3]",
   "language": "python",
   "name": "conda-env-cdat82MesaPy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
